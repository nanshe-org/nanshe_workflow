{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setup. Ignore warnings during production runs.\n",
        "\n",
        "%run ./setup_tests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify input data\n",
        "\n",
        "* `data_dir` (`str`): Where the data is located. (change if data is not in the current directory, normally is)\n",
        "* `data` (`str`): HDF5 file to use as input data.\n",
        "* `data_basename` (`str`): Basename to use for intermediate and final result files.\n",
        "* `dataset` (`str`): HDF5 dataset to use as input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"\"\n",
        "data = \"data.tif\"\n",
        "data_basename = \"data\"\n",
        "dataset = \"images\"\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "data_ext = os.path.splitext(data)[1].lower()\n",
        "data_dir = os.path.abspath(data_dir)\n",
        "\n",
        "subgroup_raw = \"raw\"\n",
        "subgroup_trim = \"trim\"\n",
        "subgroup_dn = \"dn\"\n",
        "subgroup_reg = \"reg\"\n",
        "subgroup_reg_images = \"reg/images\"\n",
        "subgroup_reg_shifts = \"reg/shifts\"\n",
        "subgroup_sub = \"sub\"\n",
        "subgroup_norm = \"norm\"\n",
        "subgroup_dict_init_data = \"dict_init_data\"\n",
        "subgroup_dict_init_dict = \"dict_init_dict\"\n",
        "subgroup_dict = \"dict\"\n",
        "subgroup_code = \"code\"\n",
        "subgroup_post = \"post\"\n",
        "subgroup_post_mask = \"post/mask\"\n",
        "subgroup_rois = \"rois\"\n",
        "subgroup_rois_masks = \"rois/masks\"\n",
        "subgroup_rois_masks_j = \"rois/masks_j\"\n",
        "subgroup_rois_labels = \"rois/labels\"\n",
        "subgroup_rois_labels_j = \"rois/labels_j\"\n",
        "subgroup_traces = \"traces\"\n",
        "subgroup_proj = \"proj\"\n",
        "subgroup_proj_hmean = \"proj/hmean\"\n",
        "subgroup_proj_max = \"proj/max\"\n",
        "subgroup_proj_mean = \"proj/mean\"\n",
        "subgroup_proj_std = \"proj/std\"\n",
        "\n",
        "postfix_rois = \"_rois\"\n",
        "postfix_traces = \"_traces\"\n",
        "postfix_html = \"_proj\"\n",
        "\n",
        "h5_ext = os.path.extsep + \"h5\"\n",
        "tiff_ext = os.path.extsep + \"tif\"\n",
        "zarr_ext = os.path.extsep + \"zarr\"\n",
        "html_ext = os.path.extsep + \"html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from psutil import cpu_count\n",
        "\n",
        "cluster_kwargs = {\n",
        "    \"ip\": \"\"\n",
        "}\n",
        "client_kwargs = {}\n",
        "adaptive_kwargs = {\n",
        "    \"minimum\": 0,\n",
        "    \"maximum\": int(os.environ.get(\"CORES\", cpu_count())) - 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zarr\n",
        "\n",
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "\n",
        "zarr_store = zarr.open_group(DistributedDirectoryStore(data_basename + zarr_ext), \"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure and startup Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import startup_distributed\n",
        "from nanshe_workflow.data import DistributedArrayStore\n",
        "\n",
        "client = startup_distributed(0, cluster_kwargs, client_kwargs, adaptive_kwargs)\n",
        "\n",
        "dask_store = DistributedArrayStore(zarr_store, client=client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define functions for computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.cm\n",
        "import matplotlib.pyplot\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mplview.core import MatplotlibViewer as MPLViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ctypes\n",
        "import logging\n",
        "import os\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "from builtins import range as irange\n",
        "\n",
        "try:\n",
        "    from contextlib import suppress\n",
        "except ImportError:\n",
        "    from contextlib2 import suppress\n",
        "\n",
        "import numpy\n",
        "import scipy\n",
        "import scipy.ndimage\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.ndimage as spim\n",
        "import h5py as hp\n",
        "\n",
        "import dask\n",
        "import dask.array\n",
        "import dask.array.fft\n",
        "import dask.distributed\n",
        "\n",
        "import dask.array as da\n",
        "\n",
        "import dask_image\n",
        "import dask_image.imread\n",
        "import dask_image.ndfilters\n",
        "import dask_image.ndfourier\n",
        "\n",
        "import zarr\n",
        "\n",
        "import nanshe\n",
        "from nanshe.imp.segment import generate_dictionary\n",
        "\n",
        "import nanshe_workflow\n",
        "import nanshe_workflow._reg_joblib\n",
        "from nanshe_workflow.data import io_remove, dask_io_remove, dask_load_hdf5, dask_store_zarr, zip_zarr, open_zarr\n",
        "\n",
        "zarr.blosc.set_nthreads(1)\n",
        "zarr.blosc.use_threads = False\n",
        "client.run(zarr.blosc.set_nthreads, 1)\n",
        "client.run(setattr, zarr.blosc, \"use_threads\", False)\n",
        "\n",
        "logging.getLogger(\"nanshe\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "from nanshe_workflow.data import hdf5_to_zarr, zarr_to_hdf5\n",
        "from nanshe_workflow.data import save_tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import pyfftw.interfaces.numpy_fft as numpy_fft\n",
        "except ImportError:\n",
        "    import numpy.fft as numpy_fft\n",
        "\n",
        "rfftn = da.fft.fft_wrap(numpy_fft.rfftn)\n",
        "irfftn = da.fft.fft_wrap(numpy_fft.irfftn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.imp2 import extract_f0, wavelet_transform, renormalized_images, normalize_data\n",
        "\n",
        "from nanshe_workflow.par import halo_block_generate_dictionary_parallel\n",
        "from nanshe_workflow.imp import block_postprocess_data_parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.proj2 import compute_traces\n",
        "\n",
        "from nanshe_workflow.proj2 import compute_adj_harmonic_mean_projection\n",
        "\n",
        "from nanshe_workflow.proj2 import norm_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Begin workflow. Set parameters and run each cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert TIFF/HDF5 to Zarr\n",
        "\n",
        "* `block_chunks` (`tuple` of `int`s): chunk size for each block loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_chunks = (100, -1, -1)\n",
        "\n",
        "for k in [subgroup_raw]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "if data_ext == tiff_ext:\n",
        "    dask_store[subgroup_raw] = dask_image.imread.imread(data, nframes=block_chunks[0])\n",
        "elif data_ext == h5_ext:\n",
        "    dask_store[subgroup_raw] = dask_load_hdf5(data, dataset, chunks=block_chunks)\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_raw], notebook=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trimming\n",
        "\n",
        "* `front` (`int`): amount to trim off the front\n",
        "* `back` (`int`): amount to trim off the back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "front = 0\n",
        "back = 0\n",
        "\n",
        "\n",
        "for k in [subgroup_trim]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "# Trim frames from front and back\n",
        "da_imgs_trim = da_imgs[front:len(da_imgs)-back]\n",
        "\n",
        "# Store trimmed data\n",
        "dask_store[subgroup_trim] = da_imgs_trim\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_trim], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Denoising\n",
        "\n",
        "* `med_filt_size` (`int`): footprint size for median filter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_filt_size = 10\n",
        "\n",
        "\n",
        "for k in [subgroup_dn]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "# Median filter frames\n",
        "da_imgs_filt = dask_image.ndfilters.median_filter(\n",
        "    da_imgs, (1,) + (da_imgs.ndim - 1) * (med_filt_size,)\n",
        ")\n",
        "\n",
        "# Reset minimum to original value.\n",
        "da_imgs_min = da_imgs.min()\n",
        "da_imgs_filt_min = da_imgs_filt.min()\n",
        "da_imgs_filt += da_imgs_min - da_imgs_filt_min\n",
        "\n",
        "# Store denoised data\n",
        "da_imgs_min, da_imgs_filt, da_imgs_filt_min = dask.persist(da_imgs_min, da_imgs_filt, da_imgs_filt_min)\n",
        "dask_store[subgroup_dn] = da_imgs_filt\n",
        "del da_imgs_min, da_imgs_filt, da_imgs_filt_min\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_dn], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fourier_shift_wrap(array, shift):\n",
        "    result = numpy.empty_like(array)\n",
        "    for i in irange(len(array)):\n",
        "        result[i] = spim.fourier_shift(array[i], shift[0][i])\n",
        "    return result\n",
        "\n",
        "\n",
        "def find_best_match(matches):\n",
        "    best_match = numpy.zeros(\n",
        "        matches.shape[:1],\n",
        "        dtype=matches.dtype\n",
        "    )\n",
        "    if matches.size:\n",
        "        i = numpy.argmin((matches ** 2).sum(axis=0))\n",
        "        best_match = matches[:, i]\n",
        "\n",
        "    return best_match\n",
        "\n",
        "\n",
        "def compute_offset(match_mask):\n",
        "    while type(match_mask) is list:\n",
        "        match_mask = match_mask[0]\n",
        "\n",
        "    result = numpy.empty((len(match_mask), match_mask.ndim - 1), dtype=int)\n",
        "    for i in irange(len(match_mask)):\n",
        "        match_mask_i = match_mask[i]\n",
        "\n",
        "        frame_shape = np.array(match_mask_i.shape)\n",
        "        half_frame_shape = frame_shape // 2\n",
        "\n",
        "        matches = np.array(match_mask_i.nonzero())\n",
        "        above = (matches > half_frame_shape[:, None]).astype(matches.dtype)\n",
        "        matches -= above * frame_shape[:, None]\n",
        "\n",
        "        result[i] = find_best_match(matches)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def roll_frames_chunk(frames, shifts):\n",
        "    # Needed as Dask shares objects and we plan to write to it.\n",
        "    # Also if there is only one refcount the old object is freed.\n",
        "    frames = numpy.copy(frames)\n",
        "\n",
        "    for i in irange(len(frames)):\n",
        "        frames[i] = numpy.roll(\n",
        "            frames[i],\n",
        "            tuple(shifts[i]),\n",
        "            axis=tuple(irange(frames.ndim - 1))\n",
        "        )\n",
        "\n",
        "    return frames\n",
        "\n",
        "\n",
        "def roll_frames(frames, shifts):\n",
        "    frames = frames.rechunk({\n",
        "        k: v for k, v in enumerate(frames.shape[1:], 1)\n",
        "    })\n",
        "    shifts = shifts.rechunk({1: shifts.shape[1]})\n",
        "\n",
        "    rolled_frames = da.atop(\n",
        "        roll_frames_chunk, tuple(irange(frames.ndim)),\n",
        "        frames, tuple(irange(frames.ndim)),\n",
        "        shifts, (0, frames.ndim),\n",
        "        dtype=da_imgs.dtype,\n",
        "        concatenate=True\n",
        "    )\n",
        "\n",
        "    return rolled_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_reps = 5\n",
        "tmpl_hist_wght = 0.25\n",
        "thld_rel_dist = 0.0\n",
        "\n",
        "\n",
        "for k in [subgroup_reg_images, subgroup_reg_shifts]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_reg]\n",
        "zarr_store.require_group(subgroup_reg)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Create frame shape arrays\n",
        "frame_shape = np.array(da_imgs_flt.shape[1:], dtype=int)\n",
        "half_frame_shape = frame_shape // 2\n",
        "frame_shape = da.asarray(frame_shape)\n",
        "half_frame_shape = da.asarray(half_frame_shape)\n",
        "\n",
        "# Find the inverse of each frame\n",
        "da_imgs_flt_min = da_imgs_flt.min()\n",
        "da_imgs_inv = dask.array.reciprocal(da_imgs_flt - (da_imgs_flt_min - 1))\n",
        "\n",
        "# Compute the FFT of inverse frames and template\n",
        "da_imgs_fft = rfftn(da_imgs_inv, axes=tuple(irange(1, da_imgs_flt.ndim)))\n",
        "da_imgs_fft_tmplt = da_imgs_fft.mean(axis=0, keepdims=True)\n",
        "\n",
        "# Initialize\n",
        "i = 0\n",
        "avg_rel_dist = 1.0\n",
        "tmpl_hist_wght = da_imgs_flt.dtype.type(tmpl_hist_wght)\n",
        "da_shifts = da.zeros(\n",
        "    (len(da_imgs_fft), da_imgs_fft.ndim - 1),\n",
        "    dtype=int,\n",
        "    chunks=(da_imgs_fft.chunks[0], (da_imgs_fft.ndim - 1,))\n",
        ")\n",
        "\n",
        "# Persist FFT of frames and template\n",
        "da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt = client.persist([\n",
        "    da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt\n",
        "])\n",
        "del da_imgs_flt_min\n",
        "\n",
        "while avg_rel_dist > thld_rel_dist and i < num_reps:\n",
        "    # Compute the shifted frames\n",
        "    da_shifted_frames = da.atop(\n",
        "        fourier_shift_wrap,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_imgs_fft,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_shifts,\n",
        "        (0, da_imgs_fft.ndim),\n",
        "        dtype=da_imgs_fft.dtype\n",
        "    )\n",
        "\n",
        "    # Compute the template FFT\n",
        "    da_imgs_fft_tmplt = (\n",
        "        tmpl_hist_wght * da_imgs_fft_tmplt +\n",
        "        (1 - tmpl_hist_wght) * da_shifted_frames.mean(axis=0, keepdims=True)\n",
        "    )\n",
        "\n",
        "    # Persist the updated FFT template\n",
        "    da_shifted_frames, da_imgs_fft_tmplt = client.persist([\n",
        "        da_shifted_frames, da_imgs_fft_tmplt\n",
        "    ])\n",
        "    del da_shifted_frames\n",
        "\n",
        "    # Find the best overlap with the template.\n",
        "    da_overlap = irfftn(\n",
        "        da_imgs_fft * da_imgs_fft_tmplt,\n",
        "        s=da_imgs_flt.shape[1:],\n",
        "        axes=tuple(irange(1, da_imgs_flt.ndim))\n",
        "    )\n",
        "    da_overlap_max = da_overlap.max(axis=tuple(irange(1, da_imgs_flt.ndim)), keepdims=True)\n",
        "    da_overlap_max_match = (da_overlap == da_overlap_max)\n",
        "\n",
        "    # Persist masks of best FFT overlaps\n",
        "    da_overlap, da_overlap_max, da_overlap_max_match = client.persist([\n",
        "        da_overlap, da_overlap_max, da_overlap_max_match\n",
        "    ])\n",
        "    del da_overlap\n",
        "    del da_overlap_max\n",
        "\n",
        "    # Compute the shift for each frame.\n",
        "    old_da_shifts = da_shifts\n",
        "    da_raw_shifts = da.atop(\n",
        "        compute_offset,\n",
        "        (0, da_overlap_max_match.ndim),\n",
        "        da_overlap_max_match.rechunk(dict(enumerate(da_overlap_max_match.shape[1:], 1))),\n",
        "        tuple(irange(0, da_overlap_max_match.ndim)),\n",
        "        dtype=int,\n",
        "        new_axes={da_overlap_max_match.ndim: da_overlap_max_match.ndim - 1}\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del da_overlap_max_match\n",
        "\n",
        "    # Remove any collective frame drift.\n",
        "    da_drift = da_raw_shifts.mean(axis=0, keepdims=True).round().astype(da_shifts.dtype)\n",
        "    da_shifts = da_raw_shifts - da_drift\n",
        "\n",
        "    # Persist drift corrected shifts\n",
        "    da_raw_shifts, da_drift, da_shifts = client.persist([\n",
        "        da_raw_shifts, da_drift, da_shifts\n",
        "    ])\n",
        "    del da_raw_shifts\n",
        "    del da_drift\n",
        "\n",
        "    # Find shift change.\n",
        "    diff_da_shifts = da_shifts - old_da_shifts\n",
        "    rel_diff_da_shifts = (\n",
        "        diff_da_shifts.astype(da_imgs_flt.dtype) / \n",
        "        frame_shape.astype(da_imgs_flt.dtype) /\n",
        "        np.sqrt(da_imgs_flt.dtype.type(len(frame_shape)))\n",
        "    )\n",
        "    rel_dist_da_shifts = da.sqrt(da.square(rel_diff_da_shifts).sum(axis=1))\n",
        "    avg_rel_dist = rel_dist_da_shifts.sum() / da_imgs_flt.dtype.type(len(da_shifts))\n",
        "\n",
        "    # Free old shifts\n",
        "    del old_da_shifts\n",
        "\n",
        "    # Persist statistics related to shift change\n",
        "    diff_da_shifts, rel_diff_da_shifts, rel_dist_da_shifts, avg_rel_dist = client.persist([\n",
        "        diff_da_shifts, rel_diff_da_shifts, rel_dist_da_shifts, avg_rel_dist\n",
        "    ])\n",
        "    del diff_da_shifts\n",
        "    del rel_diff_da_shifts\n",
        "    del rel_dist_da_shifts\n",
        "\n",
        "    # Compute change\n",
        "    dask.distributed.progress(avg_rel_dist, notebook=False)\n",
        "    print(\"\")\n",
        "    avg_rel_dist = avg_rel_dist.compute()\n",
        "    i += 1\n",
        "\n",
        "    # Show change\n",
        "    print((i, avg_rel_dist))\n",
        "\n",
        "# Drop unneeded items\n",
        "del frame_shape\n",
        "del half_frame_shape\n",
        "del da_imgs_flt\n",
        "del da_imgs_inv\n",
        "del da_imgs_fft\n",
        "del da_imgs_fft_tmplt\n",
        "\n",
        "# Roll all parts to clip to one side\n",
        "# Keep origin static\n",
        "da_imgs_shifted = roll_frames(\n",
        "    da_imgs,\n",
        "    da.clip(da_shifts, None, 0)\n",
        ")\n",
        "\n",
        "# Truncate all frames to smallest one\n",
        "da_imgs_trunc_shape = da.asarray(da_imgs.shape[1:]) - abs(da_shifts).max(axis=0)\n",
        "da_imgs_trunc_shape = da_imgs_trunc_shape.compute()\n",
        "\n",
        "da_imgs_trunc_cut = tuple(map(\n",
        "    lambda s: slice(None, s), da_imgs_trunc_shape\n",
        "))\n",
        "\n",
        "da_imgs_trunc = da_imgs_shifted[(slice(None),) + da_imgs_trunc_cut]\n",
        "\n",
        "# Free raw data\n",
        "del da_imgs\n",
        "\n",
        "# Store registered data\n",
        "dask_store.update({\n",
        "    subgroup_reg_images: da_imgs_trunc,\n",
        "    subgroup_reg_shifts: da_shifts,\n",
        "})\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_reg_images],\n",
        "        dask_store[subgroup_reg_shifts]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "# Free truncated frames and shifts\n",
        "del da_imgs_trunc\n",
        "del da_shifts\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "da_shifts = dask_store[subgroup_reg_shifts]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "fig, axs = plt.subplots(nrows=da_shifts.shape[1], sharex=True)\n",
        "fig.subplots_adjust(hspace=0.0)\n",
        "for i in range(da_shifts.shape[1]):\n",
        "    axs[i].plot(np.asarray(da_shifts[:, i]))\n",
        "    axs[i].set_ylabel(\"%s (px)\" % chr(ord(\"X\") + da_shifts.shape[1] - i - 1))\n",
        "    axs[i].yaxis.set_tick_params(width=1.5)\n",
        "    [v.set_linewidth(2) for v in axs[i].spines.values()]\n",
        "axs[-1].set_xlabel(\"Frame (#)\")\n",
        "axs[-1].set_xlim((0, da_shifts.shape[0] - 1))\n",
        "axs[-1].xaxis.set_tick_params(width=1.5)\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_proj]\n",
        "zarr_store.require_group(subgroup_proj)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_proj_hmean = compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "\n",
        "da_imgs_proj_max = da_imgs_flt.max(axis=0)\n",
        "\n",
        "da_imgs_proj_mean, da_imgs_proj_std = da_imgs_flt.mean(axis=0), da_imgs_flt.std(axis=0)\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std],\n",
        "    [da_imgs_proj_hmean, da_imgs_proj_max, da_imgs_proj_mean, da_imgs_proj_std]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_proj_hmean],\n",
        "        dask_store[subgroup_proj_max],\n",
        "        dask_store[subgroup_proj_mean],\n",
        "        dask_store[subgroup_proj_std]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtract Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_sub]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_sub = da_imgs_flt - compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "da_imgs_sub -= da_imgs_sub.min()\n",
        "\n",
        "# Store background removed data\n",
        "dask_store[subgroup_sub] = da_imgs_sub\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_sub], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_norm]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_flt_mins = da_imgs_flt.min(\n",
        "    axis=tuple(irange(1, da_imgs_flt.ndim)),\n",
        "    keepdims=True\n",
        ")\n",
        "\n",
        "da_imgs_flt_shift = da_imgs_flt - da_imgs_flt_mins\n",
        "\n",
        "da_result = renormalized_images(da_imgs_flt_shift)\n",
        "\n",
        "# Store normalized data\n",
        "dask_store[subgroup_norm] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_norm], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dictionary Learning\n",
        "\n",
        "* `n_components` (`int`): number of basis images in the dictionary.\n",
        "* `batchsize` (`int`): minibatch size to use.\n",
        "* `iters` (`int`): number of iterations to run before getting dictionary.\n",
        "* `lambda1` (`float`): weight for L<sup>1</sup> sparisty enforcement on sparse code.\n",
        "* `lambda2` (`float`): weight for L<sup>2</sup> sparisty enforcement on sparse code.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "import itertools\n",
        "import logging\n",
        "import operator\n",
        "import sys\n",
        "\n",
        "from builtins import filter as ifilter\n",
        "\n",
        "import toolz\n",
        "import toolz.itertoolz\n",
        "\n",
        "import sklearn\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.decomposition.dict_learning import SparseCodingMixin\n",
        "\n",
        "try:\n",
        "    from contextlib import ExitStack, suppress, redirect_stdout, redirect_stderr\n",
        "except ImportError:\n",
        "    from contextlib2 import ExitStack, suppress, redirect_stdout, redirect_stderr\n",
        "\n",
        "try:\n",
        "    from StringIO import StringIO\n",
        "except ImportError:\n",
        "    from io import StringIO\n",
        "\n",
        "\n",
        "def to_tuple(*args):\n",
        "    return tuple(args)\n",
        "\n",
        "\n",
        "def func_log_stdoe(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapped(*args, **kwargs):\n",
        "        with ExitStack() as stack:\n",
        "            out, err = StringIO(), StringIO()\n",
        "\n",
        "            stack.enter_context(redirect_stdout(out))\n",
        "            stack.enter_context(redirect_stdout(err))\n",
        "\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            finally:\n",
        "                logging.getLogger(\"distributed.worker.stdout\").info(out.getvalue())\n",
        "                logging.getLogger(\"distributed.worker.stderr\").info(err.getvalue())\n",
        "\n",
        "    return wrapped\n",
        "\n",
        "\n",
        "def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,\n",
        "                         return_code=True, dict_init=None, callback=None,\n",
        "                         batch_size=3, verbose=False, shuffle=True, n_jobs=1,\n",
        "                         method='lars', iter_offset=0, random_state=None,\n",
        "                         return_inner_stats=False, inner_stats=None,\n",
        "                         return_n_iter=False):\n",
        "    with sklearn.externals.joblib.parallel_backend(\"sequential\"):\n",
        "        return sklearn.decomposition.dict_learning_online(X, n_components=n_components, alpha=alpha,\n",
        "                                                          n_iter=n_iter, return_code=return_code,\n",
        "                                                          dict_init=np.require(dict_init, requirements=\"OW\"),\n",
        "                                                          callback=callback, batch_size=batch_size, verbose=verbose,\n",
        "                                                          shuffle=shuffle, n_jobs=n_jobs, method=method,\n",
        "                                                          iter_offset=iter_offset, random_state=random_state,\n",
        "                                                          return_inner_stats=return_inner_stats,\n",
        "                                                          inner_stats=inner_stats, return_n_iter=return_n_iter)\n",
        "\n",
        "\n",
        "\n",
        "class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):\n",
        "    def __init__(self,\n",
        "                 n_components=None,\n",
        "                 alpha=1,\n",
        "                 n_iter=1000,\n",
        "                 fit_algorithm=\"lars\",\n",
        "                 batch_size=3,\n",
        "                 shuffle=True,\n",
        "                 dict_init=None,\n",
        "                 transform_algorithm=\"omp\",\n",
        "                 transform_n_nonzero_coefs=None,\n",
        "                 transform_alpha=None,\n",
        "                 verbose=False):\n",
        "        self.n_components = n_components\n",
        "        self.alpha = alpha\n",
        "        self.n_iter = n_iter\n",
        "        self.fit_algorithm = fit_algorithm\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.dict_init = dict_init\n",
        "        self.transform_algorithm = transform_algorithm\n",
        "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
        "        self.transform_alpha = transform_alpha\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.components_ = self.dict_init\n",
        "        if self.components_ is not None:\n",
        "            self.components_ = da.asarray(self.components_)\n",
        "            self.components_ = self.components_.rechunk(self.components_.shape)\n",
        "\n",
        "        self.iter_offset_ = 0\n",
        "        self.inner_stats_ = None\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = da.asarray(X)\n",
        "\n",
        "        n_components = self.n_components\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        components_ = self.components_\n",
        "        inner_stats_ = self.inner_stats_\n",
        "\n",
        "        X_get = toolz.curry(\n",
        "            operator.getitem,\n",
        "            X.rechunk((1, X.shape[1]))\n",
        "        )\n",
        "        if components_ is None:\n",
        "            idx = np.random.permutation(X.shape[0])[:n_components]\n",
        "            components_ = da.stack([X_get(i) for i in idx.flat]).rechunk({0: n_components})\n",
        "        if self.shuffle:\n",
        "            idx = np.random.permutation(X.shape[0])\n",
        "            X = da.stack([X_get(i) for i in idx.flat]).rechunk({0: X.chunks[0]})\n",
        "        if inner_stats_ is None:\n",
        "            inner_stats_ = (\n",
        "                da.zeros((n_components, n_components), chunks=(n_components, n_components)),\n",
        "                da.zeros((n_features, n_components), chunks=(n_features, n_components))\n",
        "            )\n",
        "\n",
        "        func = dict_learning_online\n",
        "        if self.verbose:\n",
        "            func = func_log_stdoe(dict_learning_online)\n",
        "\n",
        "        for slc in da.core.slices_from_chunks(X.chunks):\n",
        "            X_chk = X[slc]\n",
        "\n",
        "            X_chk_key = next(dask.core.flatten(X_chk.__dask_keys__()))\n",
        "            components_key = next(dask.core.flatten(components_.__dask_keys__()))\n",
        "            inner_stats_tup_name = \"to_tuple-%s\" % dask.base.tokenize(*inner_stats_)\n",
        "\n",
        "            kwargs = dict(\n",
        "                n_components=n_components,\n",
        "                alpha=self.alpha,\n",
        "                n_iter=self.n_iter,\n",
        "                return_code=False,\n",
        "                dict_init=components_key,\n",
        "                callback=None,\n",
        "                batch_size=self.batch_size,\n",
        "                verbose=self.verbose,\n",
        "                shuffle=False,\n",
        "                n_jobs=1,\n",
        "                method=self.fit_algorithm,\n",
        "                iter_offset=self.iter_offset_,\n",
        "                random_state=None,\n",
        "                return_inner_stats=True,\n",
        "                inner_stats=inner_stats_tup_name,\n",
        "                return_n_iter=False\n",
        "            )\n",
        "\n",
        "            tok = dask.base.tokenize(X_chk_key, **kwargs)\n",
        "            dct = dask.sharedict.merge(\n",
        "                {(\"components_dict_learning_online-%s\" % tok, 0, 0): (\n",
        "                    operator.getitem, \"dict_learning_online-%s\" % tok, 0\n",
        "                )},\n",
        "                {(\"inner_stat_A_dict_learning_online-%s\" % tok, 0, 0): (\n",
        "                    operator.getitem, (operator.getitem, \"dict_learning_online-%s\" % tok, 1), 0\n",
        "                )},\n",
        "                {(\"inner_stat_B_dict_learning_online-%s\" % tok, 0, 0): (\n",
        "                    operator.getitem, (operator.getitem, \"dict_learning_online-%s\" % tok, 1), 1\n",
        "                )},\n",
        "                {\"dict_learning_online-%s\" % tok:\n",
        "                    (dask.compatibility.apply, func, [X_chk_key], kwargs),\n",
        "                },\n",
        "                X_chk.__dask_graph__(),\n",
        "                components_.__dask_graph__(),\n",
        "                {\n",
        "                    inner_stats_tup_name:\n",
        "                    (to_tuple,) + tuple(next(dask.core.flatten(e.__dask_keys__())) for e in inner_stats_)\n",
        "                },\n",
        "                *(e.__dask_graph__() for e in inner_stats_)\n",
        "            )\n",
        "\n",
        "            components_ = da.Array(\n",
        "                dct, \"components_dict_learning_online-%s\" % tok, ((n_components,), (n_features,)), X.dtype\n",
        "            )\n",
        "            inner_stats_ = (\n",
        "                da.Array(\n",
        "                    dct, \"inner_stat_A_dict_learning_online-%s\" % tok, ((n_components,), (n_components,)), X.dtype\n",
        "                ),\n",
        "                da.Array(\n",
        "                    dct, \"inner_stat_B_dict_learning_online-%s\" % tok, ((n_features,), (n_components,)), X.dtype\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            # Persist everything after an iteration\n",
        "            result = dask.persist(components_, *inner_stats_)\n",
        "            components_, inner_stats_ = result[0], result[1:]\n",
        "\n",
        "            self.iter_offset_ += self.n_iter\n",
        "\n",
        "        self.components_ = components_\n",
        "        self.inner_stats_ = inner_stats_\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _sparse_encode_wrapper(*args, **kwargs):\n",
        "        args = tuple(e[0] if isinstance(e, list) else e for e in args)\n",
        "        return sklearn.decomposition.sparse_encode(*args, **kwargs)\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        sparse_encode_wrapper = MiniBatchDictionaryLearning._sparse_encode_wrapper\n",
        "        if self.verbose:\n",
        "            sparse_encode_wrapper = func_log_stdoe(sparse_encode_wrapper)\n",
        "\n",
        "        gram = da.tensordot(self.components_, self.components_, axes=[[1], [1]])\n",
        "        cov = da.tensordot(self.components_, X, axes=[[1], [1]])\n",
        "\n",
        "        code = da.atop(\n",
        "            sparse_encode_wrapper,\n",
        "            (1, 0),\n",
        "            X,\n",
        "            (1, 2),\n",
        "            self.components_,\n",
        "            (0, 2),\n",
        "            gram,\n",
        "            (0, 0),\n",
        "            cov,\n",
        "            (0, 1),\n",
        "            dtype=self.components_.dtype,\n",
        "            algorithm=self.transform_algorithm,\n",
        "            n_nonzero_coefs=self.transform_n_nonzero_coefs,\n",
        "            alpha=self.transform_alpha,\n",
        "            copy_cov=True,\n",
        "            init=None,\n",
        "            max_iter=self.n_iter,\n",
        "            n_jobs=1,\n",
        "            check_input=False,\n",
        "            verbose=self.verbose\n",
        "        )\n",
        "        gram, cov, code = dask.persist(gram, cov, code)\n",
        "\n",
        "        return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import toolz\n",
        "\n",
        "\n",
        "n_components = 50\n",
        "\n",
        "\n",
        "for k in [subgroup_dict_init_data, subgroup_dict_init_dict]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "\n",
        "# Reshape to matrix and provide frame selector\n",
        "da_imgs_mtx = da_imgs.reshape(\n",
        "    da_imgs.shape[0],\n",
        "    int(np.prod(da_imgs.shape[1:]))\n",
        ")\n",
        "da_imgs_mtx_get = toolz.curry(\n",
        "    operator.getitem,\n",
        "    da_imgs_mtx.rechunk((1, da_imgs_mtx.shape[1]))\n",
        ")\n",
        "\n",
        "# Create shuffled data\n",
        "idx = np.random.permutation(da_imgs_mtx.shape[0])\n",
        "dict_init_data = da.stack([da_imgs_mtx_get(i) for i in idx.flat])\n",
        "dict_init_data = dict_init_data.rechunk({0: da_imgs_mtx.chunks[0]})\n",
        "\n",
        "# Create dictionary subsample\n",
        "idx = np.random.permutation(da_imgs_mtx.shape[0])[:n_components]\n",
        "dict_init_dict = da.stack([da_imgs_mtx_get(i) for i in idx.flat])\n",
        "dict_init_dict = dict_init_dict.rechunk({0: n_components})\n",
        "\n",
        "\n",
        "# Store shuffled data\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_dict_init_data, subgroup_dict_init_dict],\n",
        "    [dict_init_data, dict_init_dict]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_dict_init_data],\n",
        "        dask_store[subgroup_dict_init_dict]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import startup_distributed, shutdown_distributed\n",
        "from nanshe_workflow.data import DistributedArrayStore\n",
        "\n",
        "\n",
        "ncores = int(os.environ.get(\"CORES\", cpu_count())) - 1\n",
        "\n",
        "\n",
        "dict_client = startup_distributed(\n",
        "    1,\n",
        "    cluster_kwargs={\n",
        "        \"threads_per_worker\": ncores\n",
        "    },\n",
        "    client_kwargs={}\n",
        ")\n",
        "dict_client.run(importlib.import_module, \"nanshe_workflow._reg_joblib\")\n",
        "dict_client.run(\n",
        "    lambda n: ctypes.CDLL(ctypes.util.find_library(\"openblas\")).openblas_set_num_threads(n),\n",
        "    ncores\n",
        ")\n",
        "display(dict_client)\n",
        "\n",
        "\n",
        "dict_dask_store = DistributedArrayStore(zarr_store, client=dict_client)\n",
        "\n",
        "for k in [subgroup_dict]:\n",
        "    with suppress(KeyError):\n",
        "        del dict_dask_store[k]\n",
        "\n",
        "learner = MiniBatchDictionaryLearning(\n",
        "    n_components=len(dict_dask_store[subgroup_dict_init_data]),\n",
        "    alpha=0.2,\n",
        "    n_iter=100,\n",
        "    fit_algorithm=\"lars\",\n",
        "    batch_size=50,\n",
        "    shuffle=False,\n",
        "    dict_init=dict_dask_store[subgroup_dict_init_dict],\n",
        "    transform_algorithm=\"omp\",\n",
        "    transform_n_nonzero_coefs=None,\n",
        "    transform_alpha=0.01,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "learner.fit(dict_dask_store[subgroup_dict_init_data])\n",
        "\n",
        "dictionary = learner.components_\n",
        "dictionary = dictionary.reshape((dictionary.shape[0],) + dict_dask_store[subgroup_norm].shape[1:])\n",
        "dictionary = dictionary.persist()\n",
        "\n",
        "dict_dask_store[subgroup_dict] = dictionary\n",
        "\n",
        "del dictionary\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dict_dask_store[subgroup_dict],\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "del dict_dask_store\n",
        "shutdown_distributed(dict_client)\n",
        "del dict_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_code]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "da_imgs_mtx = da_imgs.reshape(\n",
        "    da_imgs.shape[0],\n",
        "    int(np.prod(da_imgs.shape[1:]))\n",
        ")\n",
        "\n",
        "learner.components_ = dask_store[subgroup_dict].reshape(\n",
        "    (dask_store[subgroup_dict].shape[0], int(np.prod(da_imgs.shape[1:])))\n",
        ")\n",
        "\n",
        "code = learner.transform(da_imgs_mtx)\n",
        "code = code.T\n",
        "code = code.persist()\n",
        "\n",
        "dask_store[subgroup_code] = code\n",
        "\n",
        "del learner\n",
        "del code\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask_store[subgroup_code],\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(1,2,1)\n",
        "im = plt.imshow(np.zeros_like(dask_store[subgroup_dict][0]), vmin=-0.01, vmax=0.2)\n",
        "fig.add_subplot(1,2,2)\n",
        "line, = plt.plot([], [], lw=2)\n",
        "plt.axis([0, 150, -10, 10])\n",
        "plt.show()\n",
        "\n",
        "@ipywidgets.interact(i=ipywidgets.IntSlider(min=0, max=len(dask_store[subgroup_dict])-1, step=1, value=0))\n",
        "def show_basis_code_plts(i):\n",
        "    im.set_array(dask_store[subgroup_dict][i])\n",
        "    line.set_data(np.arange(len(dask_store[subgroup_code][i])), dask_store[subgroup_code][i])\n",
        "    fig.canvas.draw_idle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Postprocessing\n",
        "\n",
        "* `significance_threshold` (`float`): number of standard deviations below which to include in \"noise\" estimate\n",
        "* `wavelet_scale` (`int`): scale of wavelet transform to apply (should be the same as the one used above)\n",
        "* `noise_threshold` (`float`): number of units of \"noise\" above which something needs to be to be significant\n",
        "* `accepted_region_shape_constraints` (`dict`): if ROIs don't match this, reduce the `wavelet_scale` once.\n",
        "* `percentage_pixels_below_max` (`float`): upper bound on ratio of ROI pixels not at max intensity vs. all ROI pixels\n",
        "* `min_local_max_distance` (`float`): minimum allowable euclidean distance between two ROIs maximum intensities\n",
        "* `accepted_neuron_shape_constraints` (`dict`): shape constraints for ROI to be kept.\n",
        "\n",
        "* `alignment_min_threshold` (`float`): similarity measure of the intensity of two ROIs images used for merging.\n",
        "* `overlap_min_threshold` (`float`): similarity measure of the masks of two ROIs used for merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "significance_threshold = 3.0\n",
        "wavelet_scale = 3\n",
        "noise_threshold = 3.0\n",
        "percentage_pixels_below_max = 0.8\n",
        "min_local_max_distance = 16.0\n",
        "\n",
        "alignment_min_threshold = 0.6\n",
        "overlap_min_threshold = 0.6\n",
        "\n",
        "\n",
        "for k in zarr_store.get(subgroup_post, {}).keys():\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[subgroup_post + \"/\" + k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_post]\n",
        "zarr_store.require_group(subgroup_post)\n",
        "\n",
        "\n",
        "imgs = dask_store._diskstore[subgroup_dict]\n",
        "da_imgs = da.from_array(imgs, chunks=((1,) + imgs.shape[1:]))\n",
        "\n",
        "result = block_postprocess_data_parallel(client)(da_imgs,\n",
        "                              **{\n",
        "                                    \"wavelet_denoising\" : {\n",
        "                                        \"estimate_noise\" : {\n",
        "                                            \"significance_threshold\" : significance_threshold\n",
        "                                        },\n",
        "                                        \"wavelet.transform\" : {\n",
        "                                            \"scale\" : wavelet_scale\n",
        "                                        },\n",
        "                                        \"significant_mask\" : {\n",
        "                                            \"noise_threshold\" : noise_threshold\n",
        "                                        },\n",
        "                                        \"accepted_region_shape_constraints\" : {\n",
        "                                            \"major_axis_length\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 25.0\n",
        "                                            }\n",
        "                                        },\n",
        "                                        \"remove_low_intensity_local_maxima\" : {\n",
        "                                            \"percentage_pixels_below_max\" : percentage_pixels_below_max\n",
        "                                        },\n",
        "                                        \"remove_too_close_local_maxima\" : {\n",
        "                                            \"min_local_max_distance\" : min_local_max_distance\n",
        "                                        },\n",
        "                                        \"accepted_neuron_shape_constraints\" : {\n",
        "                                            \"area\" : {\n",
        "                                                \"min\" : 25,\n",
        "                                                \"max\" : 600\n",
        "                                            },\n",
        "                                            \"eccentricity\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 0.9\n",
        "                                            }\n",
        "                                        }\n",
        "                                    },\n",
        "                                    \"merge_neuron_sets\" : {\n",
        "                                        \"alignment_min_threshold\" : alignment_min_threshold,\n",
        "                                        \"overlap_min_threshold\" : overlap_min_threshold,\n",
        "                                        \"fuse_neurons\" : {\n",
        "                                            \"fraction_mean_neuron_max_threshold\" : 0.01\n",
        "                                        }\n",
        "                                    }\n",
        "                              }\n",
        ")\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [\"%s/%s\" % (subgroup_post, e) for e in result.dtype.names],\n",
        "    [result[e] for e in result.dtype.names]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[\"%s/%s\" % (subgroup_post, e)]\n",
        "        for e in result.dtype.names\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROI and trace extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dask_io_remove(data_basename + postfix_rois + h5_ext, client)\n",
        "for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j, subgroup_rois]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_rois]\n",
        "zarr_store.require_group(subgroup_rois)\n",
        "\n",
        "\n",
        "da_roi_masks = dask_store[subgroup_post_mask]\n",
        "\n",
        "da_lbls = da.arange(\n",
        "    1,\n",
        "    len(da_roi_masks) + 1,\n",
        "    chunks=da_roi_masks.chunks[0],\n",
        "    dtype=np.uint64\n",
        ")\n",
        "da_lblimg = (\n",
        "    da_lbls[(slice(None),) + (da_roi_masks.ndim - 1) * (None,)] * \n",
        "    da_roi_masks.astype(np.uint64)\n",
        ").max(axis=0)\n",
        "\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j],\n",
        "    [da_roi_masks, da_roi_masks.astype(numpy.uint8), da_lblimg, da_lblimg.astype(numpy.uint8)]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[e] for e in\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_rois + h5_ext, \"w\") as f2:\n",
        "    for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]:\n",
        "        zarr.copy(dask_store._diskstore[k], f2)\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_traces + h5_ext, client)\n",
        "for k in [subgroup_traces]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_images = dask_store[subgroup_sub]\n",
        "da_masks = dask_store[subgroup_rois_masks]\n",
        "\n",
        "da_result = compute_traces(da_images, da_masks)\n",
        "\n",
        "# Store traces\n",
        "dask_store[subgroup_traces] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_traces], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_traces + h5_ext, \"w\") as f2:\n",
        "    zarr.copy(dask_store._diskstore[subgroup_traces], f2)\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")\n",
        "\n",
        "lblimg = dask_store[subgroup_rois_labels].compute()\n",
        "lblimg_msk = numpy.ma.masked_array(lblimg, mask=(lblimg==0))\n",
        "\n",
        "mplsv.viewer.matshow(lblimg_msk, alpha=0.3, cmap=mpl.cm.jet)\n",
        "\n",
        "\n",
        "mskimg = None\n",
        "mskimg_j = None\n",
        "lblimg = None\n",
        "traces = None\n",
        "traces_j = None\n",
        "\n",
        "del mskimg\n",
        "del mskimg_j\n",
        "del lblimg\n",
        "del traces\n",
        "del traces_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of workflow. Shutdown cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dask.distributed\n",
        "from nanshe_workflow.par import shutdown_distributed\n",
        "\n",
        "try:\n",
        "    del dask_store\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "client = dask.distributed.client.default_client()\n",
        "\n",
        "shutdown_distributed(client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare interactive projection graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import hashlib\n",
        "import io\n",
        "import mmap\n",
        "import textwrap\n",
        "import zlib\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "\n",
        "import bokeh.plotting\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "import bokeh.io\n",
        "import bokeh.io as bio\n",
        "\n",
        "import bokeh.embed\n",
        "import bokeh.embed as be\n",
        "\n",
        "from bokeh.models.mappers import LinearColorMapper\n",
        "\n",
        "import webcolors\n",
        "\n",
        "from bokeh.models import CustomJS, ColumnDataSource, HoverTool\n",
        "from bokeh.models.layouts import Row\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "\n",
        "from past.builtins import basestring\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, open_zarr\n",
        "from nanshe_workflow.vis import get_rgb_array, get_rgba_array, get_all_greys, masks_to_contours_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mskimg = zarr_store[subgroup_rois_masks][...]\n",
        "\n",
        "traces = zarr_store[subgroup_traces][...]\n",
        "\n",
        "imgproj_mean = zarr_store[subgroup_proj_max][...]\n",
        "imgproj_max = zarr_store[subgroup_proj_mean][...]\n",
        "imgproj_std = zarr_store[subgroup_proj_std][...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result visualization\n",
        "\n",
        "* `proj_img` (`str` or `list` of `str`): which projection or projections to plot (e.g. \"max\", \"mean\", \"std\").\n",
        "* `block_size` (`int`): size of each point on any dimension in the image in terms of pixels.\n",
        "* `roi_alpha` (`float`): transparency of the ROIs in a range of [0.0, 1.0].\n",
        "* `roi_border_width` (`int`): width of the line border on each ROI.\n",
        "\n",
        "<br>\n",
        "* `trace_plot_width` (`int`): width of the trace plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proj_img = \"std\"\n",
        "block_size = 1\n",
        "roi_alpha = 0.3\n",
        "roi_border_width = 3\n",
        "trace_plot_width = 500\n",
        "\n",
        "\n",
        "bio.curdoc().clear()\n",
        "\n",
        "grey_range = get_all_greys()\n",
        "grey_cm = LinearColorMapper(grey_range)\n",
        "\n",
        "colors_rgb = get_rgb_array(len(mskimg))\n",
        "colors_rgb = colors_rgb.tolist()\n",
        "colors_rgb = list(imap(webcolors.rgb_to_hex, colors_rgb))\n",
        "\n",
        "mskctr_pts_y, mskctr_pts_x = masks_to_contours_2d(mskimg)\n",
        "\n",
        "mskctr_pts_dtype = np.min_scalar_type(max(mskimg.shape[1:]) - 1)\n",
        "mskctr_pts_y = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_y]\n",
        "mskctr_pts_x = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_x]\n",
        "\n",
        "mskctr_srcs = ColumnDataSource(data=dict(x=mskctr_pts_x, y=mskctr_pts_y, color=colors_rgb))\n",
        "\n",
        "\n",
        "if isinstance(proj_img, basestring):\n",
        "    proj_img = [proj_img]\n",
        "else:\n",
        "    proj_img = list(proj_img)\n",
        "\n",
        "\n",
        "proj_plot_width = block_size*mskimg.shape[2]\n",
        "proj_plot_height = block_size*mskimg.shape[1]\n",
        "plot_projs = []\n",
        "\n",
        "if \"max\" in proj_img:\n",
        "    plot_max = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Max Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_max.image(image=[numpy.flipud(imgproj_max)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[imgproj_max.shape[1]], dh=[imgproj_max.shape[0]], color_mapper=grey_cm)\n",
        "    plot_max.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_max.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_max.axis)):\n",
        "        plot_max.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_max)\n",
        "\n",
        "\n",
        "if \"mean\" in proj_img:\n",
        "    plot_mean = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Mean Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_mean.image(image=[numpy.flipud(imgproj_mean)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_mean.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_mean.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_mean.axis)):\n",
        "        plot_mean.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_mean)\n",
        "\n",
        "\n",
        "if \"std\" in proj_img:\n",
        "    plot_std = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Std Dev Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_std.image(image=[numpy.flipud(imgproj_std)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_std.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_std.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_std.axis)):\n",
        "        plot_std.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_std)\n",
        "\n",
        "\n",
        "all_tr_dtype_srcs = ColumnDataSource(data=dict(traces_dtype=traces.dtype.type(0)[None]))\n",
        "all_tr_shape_srcs = ColumnDataSource(data=dict(traces_shape=traces.shape))\n",
        "all_tr_srcs = ColumnDataSource(data=dict(\n",
        "    traces=numpy.frombuffer(\n",
        "        zlib.compress(traces.tobytes()),\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "))\n",
        "tr_srcs = ColumnDataSource(data=dict(times_sel=[], traces_sel=[], colors_sel=[]))\n",
        "plot_tr = bp.Figure(plot_width=trace_plot_width, plot_height=proj_plot_height,\n",
        "                    x_range=(0.0, float(traces.shape[1])), y_range=(float(traces.min()), float(traces.max())),\n",
        "                    tools=[\"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"], title=\"ROI traces\",\n",
        "                    background_fill_color=\"black\", border_fill_color=\"black\")\n",
        "plot_tr.multi_line(\"times_sel\", \"traces_sel\", source=tr_srcs, color=\"colors_sel\")\n",
        "\n",
        "plot_tr.outline_line_color = \"white\"\n",
        "for i in irange(len(plot_tr.axis)):\n",
        "    plot_tr.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "plot_projs.append(plot_tr)\n",
        "\n",
        "\n",
        "mskctr_srcs.selected.js_on_change(\"indices\", CustomJS(\n",
        "    args=dict(\n",
        "        mskctr_srcs=mskctr_srcs,\n",
        "        all_tr_dtype_srcs=all_tr_dtype_srcs,\n",
        "        all_tr_shape_srcs=all_tr_shape_srcs,\n",
        "        all_tr_srcs=all_tr_srcs,\n",
        "        tr_srcs=tr_srcs\n",
        "    ), code=\"\"\"\n",
        "    var range = function(n){ return Array.from(Array(n).keys()); };\n",
        "\n",
        "    var traces_not_decoded = (all_tr_dtype_srcs.data['traces_dtype'] == 0);\n",
        "    var traces_dtype = all_tr_dtype_srcs.data['traces_dtype'].constructor;\n",
        "    var traces_shape = all_tr_shape_srcs.data['traces_shape'];\n",
        "    var trace_len = traces_shape[1];\n",
        "    var traces = all_tr_srcs.data['traces'];\n",
        "    if (traces_not_decoded) {\n",
        "        traces = window.pako.inflate(traces);\n",
        "        traces = new traces_dtype(traces.buffer);\n",
        "        all_tr_srcs.data['traces'] = traces;\n",
        "        all_tr_dtype_srcs.data['traces_dtype'] = 1;\n",
        "    }\n",
        "\n",
        "    var inds = cb_obj['1d'].indices;\n",
        "    var colors = mskctr_srcs.data['color'];\n",
        "    var selected = tr_srcs.data;\n",
        "\n",
        "    var times = range(trace_len);\n",
        "\n",
        "    selected['times_sel'] = [];\n",
        "    selected['traces_sel'] = [];\n",
        "    selected['colors_sel'] = [];\n",
        "\n",
        "    for (i = 0; i < inds.length; i++) {\n",
        "        var inds_i = inds[i];\n",
        "        var trace_i = traces.slice(trace_len*inds_i, trace_len*(inds_i+1));\n",
        "        var color_i = colors[inds_i];\n",
        "\n",
        "        selected['times_sel'].push(times);\n",
        "        selected['traces_sel'].push(trace_i);\n",
        "        selected['colors_sel'].push(color_i);\n",
        "    }\n",
        "\n",
        "    tr_srcs.change.emit();\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "plot_group = Row(*plot_projs)\n",
        "\n",
        "\n",
        "# Clear out the old HTML file before writing a new one.\n",
        "io_remove(data_basename + postfix_html + html_ext)\n",
        "\n",
        "\n",
        "def indent(text, spaces):\n",
        "    spaces = \" \" * int(spaces)\n",
        "    return \"\\n\".join(imap(lambda l: spaces + l, text.splitlines()))\n",
        "\n",
        "\n",
        "def base64_hash_file(fn, hn):\n",
        "    h = hashlib.new(hn)\n",
        "    with open(fn, \"r\") as fh:\n",
        "        mm = mmap.mmap(fh.fileno(), 0, prot=mmap.PROT_READ)\n",
        "        h.update(mm)\n",
        "\n",
        "    return base64.b64encode(h.digest())\n",
        "\n",
        "\n",
        "def generate_cdn(sha_type):\n",
        "    cdn_block = {}\n",
        "    html_cdn_tmplt = {\n",
        "        \"css_files\": \"\"\"<link rel=\"stylesheet\" type=\"text/css\" href=\"{url}\" integrity=\"{sha_type}-{sha_val}\" crossorigin=\"anonymous\" />\"\"\",\n",
        "        \"js_files\": \"\"\"<script type=\"text/javascript\" src=\"{url}\" integrity=\"{sha_type}-{sha_val}\" crossorigin=\"anonymous\"></script>\"\"\",\n",
        "    }\n",
        "    for res_type in html_cdn_tmplt.keys():\n",
        "        cdn_block[res_type] = []\n",
        "        for fn in getattr(bokeh.resources.Resources(mode=\"absolute\"), res_type):\n",
        "            url = \"https://cdnjs.cloudflare.com/ajax/libs/bokeh/{ver}/{fn}\".format(\n",
        "                ver=bokeh.__version__, fn=os.path.basename(fn)\n",
        "            )\n",
        "            cdn_block[res_type].append(\n",
        "                html_cdn_tmplt[res_type].format(\n",
        "                    url=url, sha_type=sha_type, sha_val=base64_hash_file(fn, sha_type).decode()\n",
        "                )\n",
        "            )\n",
        "        cdn_block[res_type] = \"\\n\".join(cdn_block[res_type])\n",
        "\n",
        "    cdn_block = \"\\n\\n\".join(cdn_block.values())\n",
        "\n",
        "    return cdn_block\n",
        "\n",
        "\n",
        "def write_html(filename, title, div, script, cdn):\n",
        "    html_tmplt = textwrap.dedent(u\"\"\"\\\n",
        "        <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>{title}</title>\n",
        "                {cdn}\n",
        "                <style>\n",
        "                  html {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                  }}\n",
        "                  body {{\n",
        "                    width: 90%;\n",
        "                    height: 100%;\n",
        "                    margin: auto;\n",
        "                    background-color: black;\n",
        "                  }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                {div}\n",
        "                {script}\n",
        "            </body>\n",
        "        </html>\n",
        "    \"\"\")\n",
        "\n",
        "    html_cont = html_tmplt.format(\n",
        "        title=title,\n",
        "        div=indent(div, 8),\n",
        "        script=indent(script, 8),\n",
        "        cdn=indent(cdn, 8),\n",
        "    )\n",
        "\n",
        "    with io.open(filename, \"w\") as fh:\n",
        "        fh.write(html_cont)\n",
        "\n",
        "\n",
        "script, div = be.components(plot_group)\n",
        "cdn = \"\\n\" + generate_cdn(\"sha384\") + \"\\n\"\n",
        "cdn += \"\"\"\n",
        "<script type=\"text/javascript\" src=\"{url}\" integrity=\"{integrity}\" crossorigin=\"anonymous\"></script>\n",
        "\"\"\".format(\n",
        "    url=\"https://cdnjs.cloudflare.com/ajax/libs/pako/{ver}/pako_inflate.min.js\",\n",
        "    integrity=\"{sha_type}-{sha_value}\",\n",
        ").format(\n",
        "    ver=\"1.0.6\",\n",
        "    sha_type=\"sha384\",\n",
        "    sha_value=\"vfctOCT+kAyhRRvZr0t63Ktb6zOZrCbLW9CIyQr9G4UMhKAabPpM3iDOI2lnXsX4\"\n",
        ")\n",
        "cdn += \"\\n\"\n",
        "\n",
        "write_html(data_basename + postfix_html + html_ext, data_basename + postfix_html, div, script, cdn)\n",
        "\n",
        "\n",
        "from IPython.display import display, IFrame\n",
        "display(IFrame(data_basename + postfix_html + html_ext, \"100%\", 1.05*proj_plot_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test teardown. Ignore warnings during production runs.\n",
        "\n",
        "%run ./teardown_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "state": {},
      "version": "1.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
